{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "#import pickle\n",
    "from utility import *\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def mlp_model_fn(features, labels, mode, params):\n",
    "  \"\"\"Model function for MLP.\"\"\"\n",
    "  \n",
    "  #TODO: need works on this\n",
    "  config = params\n",
    "\n",
    "\n",
    "  # Input Layer\n",
    "  \n",
    "  input_layer = tf.reshape( features[\"x\"], [-1, features[\"x\"].shape[1] ] )\n",
    "  #print ('feature x', features[\"x\"])\n",
    "  #print ('feature x shape', features[\"x\"].shape)\n",
    "  #print ('reshape:', input_layer)\n",
    "  #print ('reshape shape:', input_layer.shape)\n",
    "  #trans = tf.string_to_number(input_layer)\n",
    "  #print ('trans reshape:', trans)\n",
    "  #print ('reshape shape:', input_layer.shape)\n",
    "\n",
    "\n",
    "\n",
    "  # Dense Layers\n",
    "\n",
    "  hidden1 = tf.layers.dense(inputs=features[\"x\"], units=config['n_hidden1'], activation=tf.nn.relu)\n",
    "  drop_h1 = tf.layers.dropout(\n",
    "      inputs=hidden1, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  hidden2 = tf.layers.dense(inputs=drop_h1, units=config['n_hidden2'], activation=tf.nn.relu)\n",
    "  drop_h2 = tf.layers.dropout(\n",
    "      inputs=hidden2, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  if config['n_hidden3'] != None:\n",
    "    hidden3 = tf.layers.dense(inputs=drop_h2, units=config['n_hidden3'], activation=tf.nn.relu)\n",
    "    drop_h3 = tf.layers.dropout(\n",
    "        inputs=hidden3, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    logits = tf.layers.dense(inputs=drop_h3, units=config['nclasses'])\n",
    "  else:\n",
    "    logits = tf.layers.dense(inputs=drop_h2, units=config['nclasses'])\n",
    "    \n",
    "  predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=config['nclasses'])\n",
    "  print (onehot_labels)\n",
    "  print (logits)\n",
    "  loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unused_argv = ['pilot_mlp_newAPI.py', 'temp_data.csv', 'model/', 1024, 512, 256]\n",
    "\n",
    "filename = unused_argv[1]\n",
    "\n",
    "\n",
    "if os.path.isfile('ft_to_idx.npy') and os.path.isfile('nclasses.npy') and os.path.isfile('group_data.npy'):\n",
    "    ft_to_idx = np.load('ft_to_idx.npy')\n",
    "    ft_to_idx = ft_to_idx.item()\n",
    "    nclasses = np.load('nclasses.npy')\n",
    "    #f = open('group_data.pkl','r')\n",
    "    #group_data = pickle.load('group_data.pkl')\n",
    "    #group_data = np.load('group_data.npy') \n",
    "    group_data = np.load('toy_data.npy') # for proof of algo purpose, real use case should use the above line\n",
    "    group_data = group_data.item()\n",
    "\n",
    "else:\n",
    "    ft_to_idx, nclasses, group_data = prepare_file(filename)\n",
    "    np.save(\"ft_to_idx\", ft_to_idx)\n",
    "    np.save(\"nclasses\", nclasses)\n",
    "    #f = open('group_data.pkl','w')\n",
    "    #pickle.dump(group_data, f)\n",
    "    np.save(\"group_data\", group_data)\n",
    "\n",
    "#gen train sets\n",
    "train_full, test = train_dev_split(group_data, proportion = 0.8, thre=1) # should be 1000 or so\n",
    "train, dev = train_dev_split(train_full, proportion = 0.8, thre=1) # should be 1000 or so\n",
    "train_full_data, train_full_labels = gen_feed(train_full, ft_to_idx, upper_limit=5000)\n",
    "train_data, train_labels = gen_feed(train, ft_to_idx, upper_limit=5000)\n",
    "dev_data, dev_labels = gen_feed(dev, ft_to_idx, upper_limit=5000)\n",
    "test_data, test_labels = gen_feed(test, ft_to_idx, upper_limit=5000)\n",
    "train_full_data = train_full_data.astype(np.float32)\n",
    "train_data = train_data.astype(np.float32) \n",
    "dev_data = dev_data.astype(np.float32)\n",
    "test_data = test_data.astype(np.float32) \n",
    "'''\n",
    "train_data, train_labels = np.zeros((1, group_data['application/pdf'].shape[1]-1)), np.zeros((1,))\n",
    "for i in range(100):\n",
    "tmp_data, tmp_labels = subsampled_batch(ft_to_idx, group_data, class_size=100)\n",
    "train_data = np.vstack((train_data, tmp_data))\n",
    "train_labels = np.hstack((train_labels, tmp_labels))\n",
    "train_data = np.delete(train_data,0,0)\n",
    "train_labels = np.delete(train_labels,0,0)\n",
    "train_data = train_data.astype(np.float32)\n",
    "'''\n",
    "#gen dev set\n",
    "\n",
    "'''eval_data, eval_labels = subsampled_batch(ft_to_idx, group_data, class_size=100)\n",
    "eval_data = eval_data.astype(np.float32) \n",
    "'''\n",
    "# set config\n",
    "config = {}\n",
    "config['nclasses'] = int(nclasses)\n",
    "config['model_dir'] = unused_argv[2]\n",
    "config['n_hidden1'] = int(unused_argv[3])\n",
    "config['n_hidden2'] = int(unused_argv[4])\n",
    "config['n_hidden3'] = int(unused_argv[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpN9FVV3\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11ac75990>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpN9FVV3', '_save_summary_steps': 100}\n",
      "Tensor(\"one_hot:0\", shape=(16, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(16, 122), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpN9FVV3/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00843799  0.00826439  0.00682772 ...,  0.00835717  0.00936133\n",
      "   0.00759964]\n",
      " [ 0.00752864  0.00993414  0.00778624 ...,  0.01076042  0.00922261\n",
      "   0.00996662]\n",
      " [ 0.00836858  0.00853676  0.00788756 ...,  0.00812913  0.00856634\n",
      "   0.0078876 ]\n",
      " ..., \n",
      " [ 0.00701997  0.00565776  0.00852318 ...,  0.00934146  0.00866547\n",
      "   0.00663686]\n",
      " [ 0.00880503  0.00895336  0.00888936 ...,  0.00845858  0.00868442\n",
      "   0.00819053]\n",
      " [ 0.00867599  0.00764808  0.00831378 ...,  0.00851694  0.00860731\n",
      "   0.0075778 ]]\n",
      "INFO:tensorflow:loss = 4.70779, step = 1\n",
      "INFO:tensorflow:global_step/sec: 85.2707\n",
      "INFO:tensorflow:loss = 4.78508, step = 101 (1.174 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpN9FVV3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.78467.\n",
      "Tensor(\"one_hot:0\", shape=(?, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(?, 122), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-18-23:11:27\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpN9FVV3/model.ckpt-200\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-18-23:11:28\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.0119048, global_step = 200, loss = 4.78684\n",
      "----setting----\n",
      "hidden units: [1024, 1024]\n",
      "batch_size: 16\n",
      "dropout: 0.4\n",
      "----performance----\n",
      "{'loss': 4.7868433, 'global_step': 200, 'accuracy': 0.011904762}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpZokw3E\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11afeb950>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpZokw3E', '_save_summary_steps': 100}\n",
      "Tensor(\"one_hot:0\", shape=(16, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(16, 122), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpZokw3E/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00864704  0.0083078   0.00890095 ...,  0.00751473  0.00797953\n",
      "   0.00811176]\n",
      " [ 0.01615159  0.00709703  0.00998421 ...,  0.00667976  0.0051386\n",
      "   0.00593872]\n",
      " [ 0.00840206  0.00817128  0.00841687 ...,  0.00757311  0.00833916\n",
      "   0.00827738]\n",
      " ..., \n",
      " [ 0.01059958  0.00659498  0.01094566 ...,  0.00621627  0.00676569\n",
      "   0.00719838]\n",
      " [ 0.00840819  0.00896925  0.00863521 ...,  0.00772981  0.00763147\n",
      "   0.00874348]\n",
      " [ 0.0084534   0.00840889  0.00915996 ...,  0.00774552  0.00865081\n",
      "   0.00862217]]\n",
      "INFO:tensorflow:loss = 4.75839, step = 1\n",
      "INFO:tensorflow:global_step/sec: 112.001\n",
      "INFO:tensorflow:loss = 4.8114, step = 101 (0.893 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpZokw3E/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.82951.\n",
      "Tensor(\"one_hot:0\", shape=(?, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(?, 122), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-18-23:11:35\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpZokw3E/model.ckpt-200\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-18-23:11:35\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.0238095, global_step = 200, loss = 4.75514\n",
      "----setting----\n",
      "hidden units: [1024, 1024]\n",
      "batch_size: 16\n",
      "dropout: 0.2\n",
      "----performance----\n",
      "{'loss': 4.7551413, 'global_step': 200, 'accuracy': 0.023809524}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpflir9b\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11aaa9ad0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpflir9b', '_save_summary_steps': 100}\n",
      "Tensor(\"one_hot:0\", shape=(32, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(32, 122), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpflir9b/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00911443  0.00682388  0.00725783 ...,  0.00742733  0.00814778\n",
      "   0.00711383]\n",
      " [ 0.00893686  0.00752986  0.00826073 ...,  0.00880068  0.00727927\n",
      "   0.00715827]\n",
      " [ 0.01206806  0.00884433  0.00487574 ...,  0.00828246  0.00673092\n",
      "   0.00610722]\n",
      " ..., \n",
      " [ 0.0073163   0.00781476  0.00610849 ...,  0.00656636  0.00809154\n",
      "   0.0045566 ]\n",
      " [ 0.01658016  0.00346933  0.00423557 ...,  0.01629956  0.00463038\n",
      "   0.00215989]\n",
      " [ 0.00822371  0.00830396  0.00781132 ...,  0.00807771  0.00624984\n",
      "   0.00642983]]\n",
      "INFO:tensorflow:loss = 4.79966, step = 1\n",
      "INFO:tensorflow:global_step/sec: 68.2157\n",
      "INFO:tensorflow:loss = 4.80312, step = 101 (1.465 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpflir9b/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.75907.\n",
      "Tensor(\"one_hot:0\", shape=(?, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(?, 122), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-18-23:11:43\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpflir9b/model.ckpt-200\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-18-23:11:43\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.0119048, global_step = 200, loss = 4.76576\n",
      "----setting----\n",
      "hidden units: [1024, 1024]\n",
      "batch_size: 32\n",
      "dropout: 0.4\n",
      "----performance----\n",
      "{'loss': 4.7657614, 'global_step': 200, 'accuracy': 0.011904762}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a629410>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f', '_save_summary_steps': 100}\n",
      "Tensor(\"one_hot:0\", shape=(32, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(32, 122), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00789494  0.0081367   0.00851246 ...,  0.00767275  0.00822306\n",
      "   0.00816167]\n",
      " [ 0.00848283  0.00831278  0.00809816 ...,  0.00818348  0.00826845\n",
      "   0.00792199]\n",
      " [ 0.00735382  0.0084102   0.0079444  ...,  0.00700938  0.00853899\n",
      "   0.00805493]\n",
      " ..., \n",
      " [ 0.00819385  0.00839639  0.00889214 ...,  0.00835521  0.00810799\n",
      "   0.00743632]\n",
      " [ 0.00898336  0.00816143  0.00850334 ...,  0.00730266  0.00826934\n",
      "   0.00763726]\n",
      " [ 0.00832732  0.00884095  0.00852605 ...,  0.00816921  0.00770331\n",
      "   0.00767093]]\n",
      "INFO:tensorflow:loss = 4.81842, step = 1\n",
      "INFO:tensorflow:global_step/sec: 56.8824\n",
      "INFO:tensorflow:loss = 4.7983, step = 101 (1.757 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.77644.\n",
      "Tensor(\"one_hot:0\", shape=(?, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(?, 122), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-18-23:11:51\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f/model.ckpt-200\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-18-23:11:52\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.0178571, global_step = 200, loss = 4.78857\n",
      "----setting----\n",
      "hidden units: [1024, 1024]\n",
      "batch_size: 32\n",
      "dropout: 0.2\n",
      "----performance----\n",
      "{'loss': 4.7885723, 'global_step': 200, 'accuracy': 0.017857144}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "hidden_units = [[1024,1024]]#,[1024,512,256],[2048,2048],[2048,1024,512]]\n",
    "batch_sizes = [16,32]#,64,256,512]\n",
    "dropouts = [0.4,0.2]\n",
    "\n",
    "#reset config, defined in previous block\n",
    "config = {}\n",
    "config['nclasses'] = int(nclasses)\n",
    "results = []\n",
    "for hidden, batch_size, dropout in product(hidden_units,batch_sizes,dropouts):\n",
    "    config['n_hidden1'] = hidden[0]\n",
    "    config['n_hidden2'] = hidden[1]\n",
    "    try: config['n_hidden3'] = hidden[2]\n",
    "    except: config['n_hidden3'] = None\n",
    "    config['dropout'] = dropout\n",
    "    # Create the Estimator\n",
    "    mlp_classifier = tf.estimator.Estimator(\n",
    "    model_fn=mlp_model_fn, model_dir=None, params=config)\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=1000)\n",
    "\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=batch_size,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "\n",
    "    mlp_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=200,\n",
    "      hooks=[logging_hook])\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": dev_data},\n",
    "        y=dev_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "\n",
    "    eval_results = mlp_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print ('----setting----')\n",
    "    print ('hidden units:',hidden)\n",
    "    print ('batch_size:', batch_size)\n",
    "    print ('dropout:', dropout)\n",
    "    print ('----performance----')\n",
    "    print(eval_results)\n",
    "    results.append((eval_results['accuracy'], hidden, batch_size, dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.023809524, [1024, 1024], 16, 0.2), (0.017857144, [1024, 1024], 32, 0.2), (0.011904762, [1024, 1024], 16, 0.4), (0.011904762, [1024, 1024], 32, 0.4)]\n"
     ]
    }
   ],
   "source": [
    "results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpTN9N0g\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x119b9b110>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpTN9N0g', '_save_summary_steps': 100}\n",
      "Tensor(\"one_hot:0\", shape=(16, 122), dtype=float32)\n",
      "Tensor(\"dense_3/BiasAdd:0\", shape=(16, 122), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f/model.ckpt-200\n",
      "INFO:tensorflow:Saving checkpoints for 201 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00792927  0.01062003  0.00816412 ...,  0.00814622  0.00805544\n",
      "   0.00621837]\n",
      " [ 0.00840461  0.00862103  0.00841615 ...,  0.00848803  0.00802477\n",
      "   0.00786446]\n",
      " [ 0.00869583  0.00940409  0.00860878 ...,  0.00855325  0.00764133\n",
      "   0.00660394]\n",
      " ..., \n",
      " [ 0.00816972  0.01087395  0.00781386 ...,  0.00884798  0.00789675\n",
      "   0.00633459]\n",
      " [ 0.01021143  0.01129937  0.0115396  ...,  0.00626765  0.00476367\n",
      "   0.00425073]\n",
      " [ 0.00805403  0.01138504  0.00651068 ...,  0.00452662  0.00703468\n",
      "   0.00673516]]\n",
      "INFO:tensorflow:loss = 4.75988, step = 201\n",
      "INFO:tensorflow:global_step/sec: 104.868\n",
      "INFO:tensorflow:loss = 4.70938, step = 301 (0.948 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.69407.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpMIQl5f/model.ckpt-400\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         2\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         2\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         2\n",
      "          6       0.00      0.00      0.00         2\n",
      "          7       0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.00         2\n",
      "          9       0.00      0.00      0.00         2\n",
      "         10       0.00      0.00      0.00         2\n",
      "         11       0.00      0.00      0.00         2\n",
      "         12       0.00      0.00      0.00         2\n",
      "         13       0.00      0.00      0.00         2\n",
      "         14       0.00      0.00      0.00         2\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.50      0.50      0.50         2\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.00      0.00      0.00         2\n",
      "         20       0.00      0.00      0.00         2\n",
      "         21       0.00      0.00      0.00         2\n",
      "         22       0.00      0.00      0.00         2\n",
      "         23       0.02      0.50      0.04         2\n",
      "         24       0.00      0.00      0.00         2\n",
      "         25       0.00      0.00      0.00         2\n",
      "         26       0.00      0.00      0.00         2\n",
      "         27       0.00      0.00      0.00         2\n",
      "         28       0.00      0.00      0.00         2\n",
      "         29       0.00      0.00      0.00         2\n",
      "         30       0.00      0.00      0.00         2\n",
      "         31       0.00      0.00      0.00         2\n",
      "         33       0.00      0.00      0.00         2\n",
      "         34       0.00      0.00      0.00         2\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       0.00      0.00      0.00         1\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.00      0.00      0.00         1\n",
      "         39       0.00      0.00      0.00         2\n",
      "         40       0.00      0.00      0.00         2\n",
      "         41       0.00      0.00      0.00         2\n",
      "         42       0.00      0.00      0.00         2\n",
      "         43       0.00      0.00      0.00         1\n",
      "         44       0.00      0.00      0.00         1\n",
      "         45       0.00      0.00      0.00         2\n",
      "         46       0.00      0.00      0.00         1\n",
      "         47       0.00      0.00      0.00         2\n",
      "         48       0.00      0.00      0.00         2\n",
      "         50       0.00      0.00      0.00         2\n",
      "         52       0.00      0.00      0.00         2\n",
      "         53       0.00      0.00      0.00         2\n",
      "         54       0.00      0.00      0.00         2\n",
      "         55       0.00      0.00      0.00         2\n",
      "         56       0.00      0.00      0.00         1\n",
      "         57       0.00      0.00      0.00         2\n",
      "         58       0.00      0.00      0.00         1\n",
      "         60       0.00      0.00      0.00         0\n",
      "         61       0.00      0.00      0.00         2\n",
      "         62       0.00      0.00      0.00         2\n",
      "         63       0.00      0.00      0.00         2\n",
      "         64       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         2\n",
      "         66       0.00      0.00      0.00         1\n",
      "         67       0.00      0.00      0.00         2\n",
      "         68       0.00      0.00      0.00         2\n",
      "         69       0.00      0.00      0.00         2\n",
      "         70       0.00      0.00      0.00         1\n",
      "         71       0.00      0.00      0.00         2\n",
      "         72       0.00      0.00      0.00         2\n",
      "         73       0.00      0.00      0.00         2\n",
      "         74       0.00      0.00      0.00         2\n",
      "         75       0.00      0.00      0.00         2\n",
      "         76       0.00      0.00      0.00         2\n",
      "         78       0.00      0.00      0.00         2\n",
      "         79       0.00      0.00      0.00         2\n",
      "         80       0.00      0.00      0.00         2\n",
      "         81       0.00      0.00      0.00         0\n",
      "         86       0.00      0.00      0.00         2\n",
      "         90       0.00      0.00      0.00         2\n",
      "         92       0.11      1.00      0.19         2\n",
      "         93       0.00      0.00      0.00         2\n",
      "         94       0.00      0.00      0.00         2\n",
      "         95       0.00      0.00      0.00         2\n",
      "         96       0.00      0.00      0.00         2\n",
      "         97       0.00      0.00      0.00         1\n",
      "         98       0.00      0.00      0.00         2\n",
      "         99       0.00      0.00      0.00         0\n",
      "        100       0.00      0.00      0.00         1\n",
      "        103       0.00      0.00      0.00         2\n",
      "        104       0.00      0.00      0.00         1\n",
      "        105       0.00      0.00      0.00         1\n",
      "        106       0.00      0.00      0.00         1\n",
      "        107       0.00      0.00      0.00         1\n",
      "        109       0.00      0.00      0.00         1\n",
      "        110       0.00      0.00      0.00         1\n",
      "        112       0.00      0.00      0.00         1\n",
      "        113       0.00      0.00      0.00         2\n",
      "        115       0.00      0.00      0.00         2\n",
      "        116       0.00      0.00      0.00         1\n",
      "        117       0.00      0.00      0.00         1\n",
      "        119       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.01      0.02      0.01       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "best_param = results[0]\n",
    "hidden = best_param[1]\n",
    "config['n_hidden1'] = hidden[0]\n",
    "config['n_hidden2'] = hidden[1]\n",
    "try: config['n_hidden3'] = hidden[2]\n",
    "except: config['n_hidden3'] = None\n",
    "batch_size = best_param[2]\n",
    "config['dropout'] = best_param[3]\n",
    "\n",
    "# Create the Estimator\n",
    "cnn_classifier = tf.estimator.Estimator(\n",
    "model_fn=mlp_model_fn, model_dir=None, params=config)\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=2000) \n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": train_full_data},\n",
    "  y=train_full_labels,\n",
    "  batch_size=batch_size,\n",
    "  num_epochs=None,\n",
    "  shuffle=True)\n",
    "\n",
    "mlp_classifier.train(\n",
    "  input_fn=train_input_fn,\n",
    "  steps=200, # 60000\n",
    "  hooks=[logging_hook])\n",
    "\n",
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_data},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "predictions = mlp_classifier.predict(input_fn=pred_input_fn)\n",
    "predictions = list(p[\"classes\"] for p in predictions)\n",
    "\n",
    "print (classification_report(test_labels, predictions))\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
