{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # This is Notebook for File Type detection using convolutional neural network on TREC-DD dataset\n",
    " # The data used is in 3 part of 256 byte frequencies format, first 256, middle, last 256\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from utility import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  \n",
    "  config = params\n",
    "\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  \n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 256, 3, 1])\n",
    "  print('input shape:',input_layer.shape)\n",
    "    \n",
    "  #input_dropout = tf.layers.dropout(\n",
    "  #    inputs=input_layer, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "\n",
    "  # kernel_size specifies [width, height]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[config['kernel1_width'], 1],\n",
    "      padding=\"same\",\n",
    "      activation=None)\n",
    "  print('conv1 shpae:',conv1.shape)  \n",
    "  normal_1 = tf.layers.batch_normalization(conv1, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  relu1 = tf.nn.relu(normal_1)\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=relu1, pool_size=[config['pool1_width'], 1], strides=[config['pool1_stride'],1])\n",
    "  print('pool1 shape:',pool1.shape)\n",
    "  dropout1 = tf.layers.dropout(\n",
    "      inputs=pool1, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  \n",
    " \n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=dropout1,\n",
    "      filters=64,\n",
    "      kernel_size=[config['kernel2_width'], 1],\n",
    "      padding=\"same\",\n",
    "      activation=None)\n",
    "  print('conv2 shpae:',conv2.shape)\n",
    "  normal_2 = tf.layers.batch_normalization(conv2, training=mode == tf.estimator.ModeKeys.TRAIN)  \n",
    "  relu2 = tf.nn.relu(normal_2)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=relu2, pool_size=[config['pool2_width'], 1], strides=[config['pool2_stride'],1])\n",
    "  print('pool2 shape:',pool2.shape)\n",
    "  dropout2 = tf.layers.dropout(\n",
    "      inputs=pool2, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)  \n",
    "\n",
    "  \n",
    "  conv3 = tf.layers.conv2d(\n",
    "      inputs=dropout2,\n",
    "      filters=128,\n",
    "      kernel_size=[config['kernel2_width'], 1],\n",
    "      padding=\"same\",\n",
    "      activation=None)\n",
    "  print('conv3 shpae:',conv3.shape)\n",
    "  normal_3 = tf.layers.batch_normalization(conv3, training=mode == tf.estimator.ModeKeys.TRAIN)  \n",
    "  relu3 = tf.nn.relu(normal_3)\n",
    "  pool3 = tf.layers.max_pooling2d(inputs=relu3, pool_size=[config['pool2_width'], 1], strides=[config['pool2_stride'],1])\n",
    "  print('pool3 shape:',pool3.shape)\n",
    "  dropout3 = tf.layers.dropout(\n",
    "      inputs=pool3, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  '''\n",
    "  conv4 = tf.layers.conv2d(\n",
    "      inputs=dropout3,\n",
    "      filters=256,\n",
    "      kernel_size=[config['kernel2_width'], 1],\n",
    "      padding=\"same\",\n",
    "      activation=None)\n",
    "  print('conv4 shpae:',conv4.shape)\n",
    "  normal_4 = tf.layers.batch_normalization(conv4, training=mode == tf.estimator.ModeKeys.TRAIN)  \n",
    "  relu4 = tf.nn.relu(normal_4)\n",
    "  #pool4 = tf.layers.max_pooling2d(inputs=relu4, pool_size=[config['pool2_width'], 1], strides=[config['pool2_stride'],1])\n",
    "  #print('pool4 shape:',pool4.shape)\n",
    "  dropout4 = tf.layers.dropout(\n",
    "      inputs=relu4, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "   \n",
    "  conv5 = tf.layers.conv2d(\n",
    "      inputs=dropout4,\n",
    "      filters=128,\n",
    "      kernel_size=[config['kernel2_width'], 1],\n",
    "      padding=\"same\",\n",
    "      activation=None)\n",
    "  print('conv5 shpae:',conv5.shape)\n",
    "  normal_5 = tf.layers.batch_normalization(conv5, training=mode == tf.estimator.ModeKeys.TRAIN)  \n",
    "  relu5 = tf.nn.relu(normal_5)\n",
    "  #pool5 = tf.layers.max_pooling2d(inputs=relu5, pool_size=[config['pool2_width'], 1], strides=[config['pool2_stride'],1])\n",
    "  #print('pool5 shape:',pool5.shape)\n",
    "  dropout5 = tf.layers.dropout(\n",
    "      inputs=relu5, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  '''\n",
    "  \n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 64, 1, 64]\n",
    "  # Output Tensor Shape: [batch_size, 64 * 1* 64]]\n",
    "  dropout3_shape = dropout3.shape\n",
    "  pool3_flat = tf.reshape(dropout3, [-1, dropout3_shape[1] * dropout3_shape[2] * dropout3_shape[3]])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 64 * 1* 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool3_flat, units=config['dense_units'], activation=None)\n",
    "  dense_norm = tf.layers.batch_normalization(dense, training=mode == tf.estimator.ModeKeys.TRAIN)  \n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense_norm, rate=config['dropout'], training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 93]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=config['nclasses'])\n",
    "\n",
    "    \n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=config['nclasses'])\n",
    "  loss = tf.losses.softmax_cross_entropy(\n",
    "      onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unused_argv = ['pilot_1d_cnn_newAPI.py', 'temp_data.csv', 'model/', 1024, 512, 256]\n",
    "filename = unused_argv[1]\n",
    "\n",
    "if os.path.isfile('ft_to_idx.npy') and os.path.isfile('idx_to_ft.npy') and os.path.isfile('nclasses.npy') and os.path.isfile('group_data.npy'):\n",
    "    ft_to_idx = np.load('ft_to_idx.npy')\n",
    "    ft_to_idx = ft_to_idx.item()\n",
    "    idx_to_ft = np.load('idx_to_ft.npy')\n",
    "    idx_to_ft = idx_to_ft.item()\n",
    "    nclasses = np.load('nclasses.npy')\n",
    "    #f = open('group_data.pkl','r')\n",
    "    #group_data = pickle.load('group_data.pkl')\n",
    "    #group_data = np.load('group_data.npy') \n",
    "    group_data = np.load('toy_data.npy') # for proof of algo purpose, real use case should use the above line\n",
    "    group_data = group_data.item()\n",
    "\n",
    "else:\n",
    "    ft_to_idx, idx_to_ft, nclasses, group_data = prepare_file(filename)\n",
    "    np.save(\"ft_to_idx\", ft_to_idx)\n",
    "    np.save(\"idx_to_ft\", idx_to_ft)\n",
    "    np.save(\"nclasses\", nclasses)\n",
    "    #f = open('group_data.pkl','w')\n",
    "    #pickle.dump(group_data, f)\n",
    "    np.save(\"group_data\", group_data)\n",
    "\n",
    "#gen train set\n",
    "cnt = map(lambda x: len(x),group_data.values())\n",
    "percentile_40 = np.percentile(cnt, 40)\n",
    "train, dev ,test = train_dev_test_split(group_data, proportion = [0.6,0.2], thre = percentile_40) # should be 1000 or so\n",
    "train_data, train_labels = gen_feed(train, ft_to_idx, upper_limit=12000)\n",
    "del train,group_data\n",
    "dev_data, dev_labels = gen_feed(dev, ft_to_idx, upper_limit=3000)\n",
    "del dev\n",
    "test_data, test_labels = gen_feed(test, ft_to_idx, upper_limit=3000)\n",
    "del test\n",
    "train_data = train_data.astype(np.float32) \n",
    "dev_data = dev_data.astype(np.float32)\n",
    "test_data = test_data.astype(np.float32) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_norm = scaler.fit_transform(train_data)\n",
    "dev_data_norm = scaler.transform(dev_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 2.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 2.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 2.000000\n",
      "pool1_width  ==> 2.000000\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpgYx1Rp\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a989590>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpgYx1Rp', '_save_summary_steps': 100}\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 128, 3, 32)\n",
      "conv2 shpae: (?, 128, 3, 64)\n",
      "pool2 shape: (?, 64, 3, 64)\n",
      "conv3 shpae: (?, 64, 3, 128)\n",
      "pool3 shape: (?, 32, 3, 128)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpgYx1Rp/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00122967  0.0123742   0.00230491 ...,  0.00372666  0.00159039\n",
      "   0.00782116]\n",
      " [ 0.00133542  0.00685108  0.02395464 ...,  0.02182035  0.06164827\n",
      "   0.00500854]\n",
      " [ 0.00563035  0.00133922  0.02021297 ...,  0.05996036  0.00161142\n",
      "   0.00682479]\n",
      " ..., \n",
      " [ 0.02760082  0.00031447  0.06730452 ...,  0.01356177  0.0117837\n",
      "   0.00259866]\n",
      " [ 0.00510506  0.01126186  0.0266995  ...,  0.00948646  0.00490184\n",
      "   0.00528025]\n",
      " [ 0.00761043  0.01204784  0.0198096  ...,  0.05012077  0.00255608\n",
      "   0.07138143]]\n",
      "INFO:tensorflow:loss = 4.9607, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.38809\n",
      "INFO:tensorflow:loss = 4.54753, step = 101 (72.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.28911\n",
      "INFO:tensorflow:loss = 4.28158, step = 201 (77.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4076\n",
      "INFO:tensorflow:loss = 4.14591, step = 301 (71.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49363\n",
      "INFO:tensorflow:loss = 4.78831, step = 401 (66.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.39264\n",
      "INFO:tensorflow:loss = 4.75829, step = 501 (71.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4204\n",
      "INFO:tensorflow:loss = 4.67755, step = 601 (70.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51963\n",
      "INFO:tensorflow:loss = 4.56116, step = 701 (65.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52015\n",
      "INFO:tensorflow:loss = 3.4022, step = 801 (65.783 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 858 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpgYx1Rp/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.49955\n",
      "INFO:tensorflow:loss = 4.28922, step = 901 (66.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52599\n",
      "INFO:tensorflow:loss = 3.74054, step = 1001 (65.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47675\n",
      "INFO:tensorflow:loss = 4.30659, step = 1101 (67.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53697\n",
      "INFO:tensorflow:loss = 4.53314, step = 1201 (65.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.58374\n",
      "INFO:tensorflow:loss = 4.41828, step = 1301 (63.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57771\n",
      "INFO:tensorflow:loss = 4.28756, step = 1401 (63.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50606\n",
      "INFO:tensorflow:loss = 4.24012, step = 1501 (66.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59217\n",
      "INFO:tensorflow:loss = 3.23092, step = 1601 (62.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54029\n",
      "INFO:tensorflow:loss = 4.21096, step = 1701 (64.923 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1780 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpgYx1Rp/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.4956\n",
      "INFO:tensorflow:loss = 4.19301, step = 1801 (66.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52291\n",
      "INFO:tensorflow:loss = 4.22991, step = 1901 (65.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52271\n",
      "INFO:tensorflow:loss = 3.10114, step = 2001 (65.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42103\n",
      "INFO:tensorflow:loss = 3.45474, step = 2101 (70.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.59053\n",
      "INFO:tensorflow:loss = 3.18215, step = 2201 (62.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.67895\n",
      "INFO:tensorflow:loss = 2.84889, step = 2301 (59.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.66457\n",
      "INFO:tensorflow:loss = 2.59217, step = 2401 (60.075 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2487 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpgYx1Rp/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.89136.\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 128, 3, 32)\n",
      "conv2 shpae: (?, 128, 3, 64)\n",
      "pool2 shape: (?, 64, 3, 64)\n",
      "conv3 shpae: (?, 64, 3, 128)\n",
      "pool3 shape: (?, 32, 3, 128)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-06-19:13:21\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpgYx1Rp/model.ckpt-2487\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-06-19:13:45\n",
      "INFO:tensorflow:Saving dict for global step 2487: accuracy = 0.147454, global_step = 2487, loss = 3.671\n",
      "\n",
      "----setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 2.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 2.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 2.000000\n",
      "pool1_width  ==> 2.000000\n",
      "----performance----\n",
      "{'loss': 3.6709993, 'global_step': 2487, 'accuracy': 0.14745374}\n",
      "\n",
      "\n",
      "\n",
      "----setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 2.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 4.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 2.000000\n",
      "pool1_width  ==> 4.000000\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpGKQhrd\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a2baa90>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpGKQhrd', '_save_summary_steps': 100}\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 127, 3, 32)\n",
      "conv2 shpae: (?, 127, 3, 64)\n",
      "pool2 shape: (?, 62, 3, 64)\n",
      "conv3 shpae: (?, 62, 3, 128)\n",
      "pool3 shape: (?, 30, 3, 128)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpGKQhrd/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00493024  0.01031551  0.00451847 ...,  0.00822651  0.00589379\n",
      "   0.03493752]\n",
      " [ 0.0071242   0.00784828  0.03849944 ...,  0.00658254  0.00517156\n",
      "   0.0031404 ]\n",
      " [ 0.00106271  0.01309087  0.00364964 ...,  0.00536368  0.0039831\n",
      "   0.04113114]\n",
      " ..., \n",
      " [ 0.00102091  0.00184704  0.00186328 ...,  0.00658426  0.00615603\n",
      "   0.11629029]\n",
      " [ 0.00216495  0.00334223  0.00798594 ...,  0.00243118  0.00311515\n",
      "   0.04247919]\n",
      " [ 0.03014761  0.01396859  0.00549029 ...,  0.00594822  0.00214625\n",
      "   0.01187992]]\n",
      "INFO:tensorflow:loss = 4.96321, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.4888\n",
      "INFO:tensorflow:loss = 4.56809, step = 101 (67.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38144\n",
      "INFO:tensorflow:loss = 2.77604, step = 201 (72.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45315\n",
      "INFO:tensorflow:loss = 4.49984, step = 301 (68.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52951\n",
      "INFO:tensorflow:loss = 4.26883, step = 401 (65.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49641\n",
      "INFO:tensorflow:loss = 4.18269, step = 501 (66.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52987\n",
      "INFO:tensorflow:loss = 4.66698, step = 601 (65.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48232\n",
      "INFO:tensorflow:loss = 4.54726, step = 701 (67.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.48394\n",
      "INFO:tensorflow:loss = 4.4501, step = 801 (67.388 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 891 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpGKQhrd/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.5256\n",
      "INFO:tensorflow:loss = 4.21622, step = 901 (65.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.47675\n",
      "INFO:tensorflow:loss = 0.873495, step = 1001 (67.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49132\n",
      "INFO:tensorflow:loss = 4.2483, step = 1101 (67.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49973\n",
      "INFO:tensorflow:loss = 4.21872, step = 1201 (66.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50687\n",
      "INFO:tensorflow:loss = 4.21157, step = 1301 (66.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.4908\n",
      "INFO:tensorflow:loss = 3.92791, step = 1401 (67.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51121\n",
      "INFO:tensorflow:loss = 4.24212, step = 1501 (66.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50499\n",
      "INFO:tensorflow:loss = 3.92543, step = 1601 (66.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43779\n",
      "INFO:tensorflow:loss = 3.72989, step = 1701 (69.551 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1778 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpGKQhrd/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.36936\n",
      "INFO:tensorflow:loss = 3.38684, step = 1801 (73.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.43251\n",
      "INFO:tensorflow:loss = 3.85416, step = 1901 (69.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45999\n",
      "INFO:tensorflow:loss = 4.10428, step = 2001 (68.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.46331\n",
      "INFO:tensorflow:loss = 3.97001, step = 2101 (68.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30146\n",
      "INFO:tensorflow:loss = 3.22414, step = 2201 (76.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38989\n",
      "INFO:tensorflow:loss = 3.91225, step = 2301 (71.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52481\n",
      "INFO:tensorflow:loss = 3.8778, step = 2401 (65.584 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2487 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpGKQhrd/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.79607.\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 127, 3, 32)\n",
      "conv2 shpae: (?, 127, 3, 64)\n",
      "pool2 shape: (?, 62, 3, 64)\n",
      "conv3 shpae: (?, 62, 3, 128)\n",
      "pool3 shape: (?, 30, 3, 128)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-06-19:42:11\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpGKQhrd/model.ckpt-2487\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-06-19:42:35\n",
      "INFO:tensorflow:Saving dict for global step 2487: accuracy = 0.27267, global_step = 2487, loss = 3.56155\n",
      "\n",
      "----setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 2.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 4.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 2.000000\n",
      "pool1_width  ==> 4.000000\n",
      "----performance----\n",
      "{'loss': 3.5615525, 'global_step': 2487, 'accuracy': 0.27266961}\n",
      "\n",
      "\n",
      "\n",
      "----setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 16.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 2.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 16.000000\n",
      "pool1_width  ==> 2.000000\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11b5ef410>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO', '_save_summary_steps': 100}\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 128, 3, 32)\n",
      "conv2 shpae: (?, 128, 3, 64)\n",
      "pool2 shape: (?, 64, 3, 64)\n",
      "conv3 shpae: (?, 64, 3, 128)\n",
      "pool3 shape: (?, 32, 3, 128)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00423778  0.02368596  0.00926378 ...,  0.01266597  0.00363294\n",
      "   0.00368737]\n",
      " [ 0.00991932  0.01990946  0.0024721  ...,  0.02774013  0.01503798\n",
      "   0.01039201]\n",
      " [ 0.00369748  0.03608086  0.01079546 ...,  0.06441691  0.01928783\n",
      "   0.00893135]\n",
      " ..., \n",
      " [ 0.03480263  0.00039171  0.01835514 ...,  0.00006718  0.00880866\n",
      "   0.00505159]\n",
      " [ 0.0120869   0.06197507  0.01145877 ...,  0.04877864  0.00502168\n",
      "   0.01491456]\n",
      " [ 0.01387789  0.00826998  0.00608795 ...,  0.01762806  0.00812996\n",
      "   0.0076264 ]]\n",
      "INFO:tensorflow:loss = 4.75704, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.660756\n",
      "INFO:tensorflow:loss = 4.31361, step = 101 (151.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660507\n",
      "INFO:tensorflow:loss = 3.19474, step = 201 (151.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.722263\n",
      "INFO:tensorflow:loss = 4.72853, step = 301 (138.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.745607\n",
      "INFO:tensorflow:loss = 4.70629, step = 401 (134.119 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 420 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.725803\n",
      "INFO:tensorflow:loss = 4.35528, step = 501 (137.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.710259\n",
      "INFO:tensorflow:loss = 4.59765, step = 601 (140.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.749948\n",
      "INFO:tensorflow:loss = 4.5203, step = 701 (133.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.779944\n",
      "INFO:tensorflow:loss = 4.45749, step = 801 (128.214 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 868 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.76602\n",
      "INFO:tensorflow:loss = 4.2007, step = 901 (130.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.730596\n",
      "INFO:tensorflow:loss = 4.17031, step = 1001 (136.875 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.736448\n",
      "INFO:tensorflow:loss = 2.80022, step = 1101 (135.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.742496\n",
      "INFO:tensorflow:loss = 3.43259, step = 1201 (134.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.743302\n",
      "INFO:tensorflow:loss = 3.05022, step = 1301 (134.535 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1311 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.74368\n",
      "INFO:tensorflow:loss = 3.38916, step = 1401 (134.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.781139\n",
      "INFO:tensorflow:loss = 4.32463, step = 1501 (128.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.779285\n",
      "INFO:tensorflow:loss = 4.34491, step = 1601 (128.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.777471\n",
      "INFO:tensorflow:loss = 4.05243, step = 1701 (128.622 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1775 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.760627\n",
      "INFO:tensorflow:loss = 4.06589, step = 1801 (131.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.771188\n",
      "INFO:tensorflow:loss = 0.478617, step = 1901 (129.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.78761\n",
      "INFO:tensorflow:loss = 3.95988, step = 2001 (126.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.785521\n",
      "INFO:tensorflow:loss = 4.10051, step = 2101 (127.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.786706\n",
      "INFO:tensorflow:loss = 4.02829, step = 2201 (127.113 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2243 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.759267\n",
      "INFO:tensorflow:loss = 3.8874, step = 2301 (131.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.775306\n",
      "INFO:tensorflow:loss = 3.71793, step = 2401 (128.981 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2487 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.57559.\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 128, 3, 32)\n",
      "conv2 shpae: (?, 128, 3, 64)\n",
      "pool2 shape: (?, 64, 3, 64)\n",
      "conv3 shpae: (?, 64, 3, 128)\n",
      "pool3 shape: (?, 32, 3, 128)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-06-20:38:07\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpwoJ0xO/model.ckpt-2487\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-06-20:39:23\n",
      "INFO:tensorflow:Saving dict for global step 2487: accuracy = 0.127648, global_step = 2487, loss = 3.69169\n",
      "\n",
      "----setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 16.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 2.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 16.000000\n",
      "pool1_width  ==> 2.000000\n",
      "----performance----\n",
      "{'loss': 3.6916864, 'global_step': 2487, 'accuracy': 0.12764758}\n",
      "\n",
      "\n",
      "\n",
      "----setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 16.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 4.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 16.000000\n",
      "pool1_width  ==> 4.000000\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11b280bd0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY', '_save_summary_steps': 100}\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 127, 3, 32)\n",
      "conv2 shpae: (?, 127, 3, 64)\n",
      "pool2 shape: (?, 62, 3, 64)\n",
      "conv3 shpae: (?, 62, 3, 128)\n",
      "pool3 shape: (?, 30, 3, 128)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00477313  0.0082535   0.00482255 ...,  0.01671737  0.02142717\n",
      "   0.00513813]\n",
      " [ 0.02352466  0.01713423  0.04211247 ...,  0.00493933  0.00168356\n",
      "   0.02744093]\n",
      " [ 0.00111661  0.01015335  0.01046545 ...,  0.01081549  0.0320921\n",
      "   0.00161224]\n",
      " ..., \n",
      " [ 0.00351726  0.04760636  0.00272166 ...,  0.0061542   0.00242484\n",
      "   0.0126376 ]\n",
      " [ 0.00513819  0.00370879  0.0054461  ...,  0.00314731  0.00666761\n",
      "   0.00060241]\n",
      " [ 0.00575982  0.00282567  0.04292236 ...,  0.00062148  0.002263\n",
      "   0.00794413]]\n",
      "INFO:tensorflow:loss = 4.94804, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.768457\n",
      "INFO:tensorflow:loss = 4.75191, step = 101 (130.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.770822\n",
      "INFO:tensorflow:loss = 4.72532, step = 201 (129.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.762651\n",
      "INFO:tensorflow:loss = 4.51166, step = 301 (131.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.766832\n",
      "INFO:tensorflow:loss = 4.37507, step = 401 (130.405 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 462 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.747216\n",
      "INFO:tensorflow:loss = 1.09472, step = 501 (133.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.723413\n",
      "INFO:tensorflow:loss = 4.5694, step = 601 (138.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.724136\n",
      "INFO:tensorflow:loss = 4.40269, step = 701 (138.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.741554\n",
      "INFO:tensorflow:loss = 4.38197, step = 801 (134.849 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 894 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.686683\n",
      "INFO:tensorflow:loss = 4.20649, step = 901 (145.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.669275\n",
      "INFO:tensorflow:loss = 4.21676, step = 1001 (149.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.77168\n",
      "INFO:tensorflow:loss = 4.16114, step = 1101 (129.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.770391\n",
      "INFO:tensorflow:loss = 4.14612, step = 1201 (129.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.781853\n",
      "INFO:tensorflow:loss = 3.79976, step = 1301 (127.901 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1342 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.767756\n",
      "INFO:tensorflow:loss = 4.20849, step = 1401 (130.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.769236\n",
      "INFO:tensorflow:loss = 4.19401, step = 1501 (129.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.782996\n",
      "INFO:tensorflow:loss = 4.22615, step = 1601 (127.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.782707\n",
      "INFO:tensorflow:loss = 3.22242, step = 1701 (127.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.779365\n",
      "INFO:tensorflow:loss = 3.78171, step = 1801 (128.311 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1808 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.727827\n",
      "INFO:tensorflow:loss = 3.821, step = 1901 (137.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.781555\n",
      "INFO:tensorflow:loss = 3.89552, step = 2001 (127.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.776001\n",
      "INFO:tensorflow:loss = 3.41134, step = 2101 (128.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.768253\n",
      "INFO:tensorflow:loss = 4.05804, step = 2201 (130.165 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2266 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.74824\n",
      "INFO:tensorflow:loss = 4.02368, step = 2301 (133.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.776143\n",
      "INFO:tensorflow:loss = 3.8772, step = 2401 (128.842 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2487 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.34067.\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 127, 3, 32)\n",
      "conv2 shpae: (?, 127, 3, 64)\n",
      "pool2 shape: (?, 62, 3, 64)\n",
      "conv3 shpae: (?, 62, 3, 128)\n",
      "pool3 shape: (?, 30, 3, 128)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-06-21:34:23\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmprn7YeY/model.ckpt-2487\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-06-21:35:37\n",
      "INFO:tensorflow:Saving dict for global step 2487: accuracy = 0.170608, global_step = 2487, loss = 3.70888\n",
      "\n",
      "----setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 16.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 4.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 16.000000\n",
      "pool1_width  ==> 4.000000\n",
      "----performance----\n",
      "{'loss': 3.7088778, 'global_step': 2487, 'accuracy': 0.17060792}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "dense_units = [128]#256,512]# \n",
    "batch_sizes = [128]# 64,256,512]\n",
    "dropouts = [0.1]#0.4,0.2, 0.6]\n",
    "kernel_width = [2,16]#,8]#4,5,7]\n",
    "pool_width = [2,4]\n",
    "pool_stride = [2]#,4] 4 will be too large\n",
    "\n",
    "\n",
    "#reset config, defined in previous block\n",
    "config = {}\n",
    "config['nclasses'] =  len(np.unique(train_labels))\n",
    "results = []\n",
    "for dense_unit,batch_size,dropout,kernel_width,pool_width,pool_stride in product(dense_units,batch_sizes,dropouts,kernel_width,pool_width,pool_stride):\n",
    "    config['dropout'] = dropout\n",
    "    config['dense_units'] = dense_unit\n",
    "    config['kernel1_width'] = kernel_width\n",
    "    config['kernel2_width'] = kernel_width\n",
    "    config['pool1_width'] = pool_width\n",
    "    config['pool2_width'] = pool_width\n",
    "    config['pool1_stride'] = pool_stride\n",
    "    config['pool2_stride'] = pool_stride\n",
    "    print ('\\n----setting----')\n",
    "    print('{0:12} ==> {1:5d}'.format('batch_size', batch_size))\n",
    "    for k,v in config.iteritems():\n",
    "        print('{0:12} ==> {1:5f}'.format(k, v))  \n",
    "    # Create the Estimator\n",
    "    cnn_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=None, params=config)\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=5000) \n",
    "\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=batch_size,\n",
    "      num_epochs=3,\n",
    "      shuffle=True)\n",
    "\n",
    "    steps = train_data.shape[0]/batch_size\n",
    "    cnn_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=None, # 60000\n",
    "      hooks=[logging_hook])\n",
    "\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": dev_data},\n",
    "        y=dev_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "\n",
    "    eval_results = cnn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print ('\\n----setting----')\n",
    "    print('{0:12} ==> {1:5d}'.format('batch_size', batch_size))\n",
    "    for k,v in config.iteritems():\n",
    "        print('{0:12} ==> {1:5f}'.format(k, v))  \n",
    "    print ('----performance----')\n",
    "    print(eval_results)\n",
    "    print ('\\n')\n",
    "    results.append((eval_results['accuracy'], batch_size, dropout, dense_unit, kernel_width, pool_width, pool_stride))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.27266961, 128, 0.1, 128, 2, 4, 2), (0.17060792, 128, 0.1, 128, 16, 4, 2), (0.14745374, 128, 0.1, 128, 2, 2, 2), (0.12764758, 128, 0.1, 128, 16, 2, 2)]\n"
     ]
    }
   ],
   "source": [
    "results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpv4NXhM\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1193c4350>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpv4NXhM', '_save_summary_steps': 100}\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 127, 3, 32)\n",
      "conv2 shpae: (?, 127, 3, 64)\n",
      "pool2 shape: (?, 62, 3, 64)\n",
      "conv3 shpae: (?, 62, 3, 128)\n",
      "pool3 shape: (?, 30, 3, 128)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpv4NXhM/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.00687932  0.04560441  0.00477068 ...,  0.00684431  0.00327733\n",
      "   0.00762781]\n",
      " [ 0.01354787  0.00145669  0.01959228 ...,  0.00500759  0.00511775\n",
      "   0.0072042 ]\n",
      " [ 0.00890376  0.03721653  0.0055995  ...,  0.00821127  0.01959256\n",
      "   0.01076949]\n",
      " ..., \n",
      " [ 0.00620931  0.00470938  0.01516444 ...,  0.01530852  0.01303661\n",
      "   0.0027174 ]\n",
      " [ 0.02575935  0.00131249  0.0034538  ...,  0.01289202  0.01233038\n",
      "   0.04463388]\n",
      " [ 0.00646734  0.00523892  0.00843414 ...,  0.01837296  0.00444482\n",
      "   0.00343619]]\n",
      "INFO:tensorflow:loss = 4.94438, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.20478\n",
      "INFO:tensorflow:loss = 4.5554, step = 101 (83.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.23266\n",
      "INFO:tensorflow:loss = 4.57679, step = 201 (81.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.2277\n",
      "INFO:tensorflow:loss = 3.94724, step = 301 (81.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55744\n",
      "INFO:tensorflow:loss = 4.01123, step = 401 (64.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.5093\n",
      "INFO:tensorflow:loss = 3.84544, step = 501 (66.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57286\n",
      "INFO:tensorflow:loss = 4.46389, step = 601 (63.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.55583\n",
      "INFO:tensorflow:loss = 4.40983, step = 701 (64.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.51648\n",
      "INFO:tensorflow:loss = 4.52193, step = 801 (65.942 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 846 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpv4NXhM/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.46161\n",
      "INFO:tensorflow:loss = 4.51659, step = 901 (68.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.34925\n",
      "INFO:tensorflow:loss = 4.21787, step = 1001 (74.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.16787\n",
      "INFO:tensorflow:loss = 4.12654, step = 1101 (85.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32824\n",
      "INFO:tensorflow:loss = 3.87431, step = 1201 (75.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.49952\n",
      "INFO:tensorflow:loss = 3.8291, step = 1301 (66.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.54242\n",
      "INFO:tensorflow:loss = 4.29236, step = 1401 (64.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52176\n",
      "INFO:tensorflow:loss = 4.30865, step = 1501 (65.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52074\n",
      "INFO:tensorflow:loss = 4.28875, step = 1601 (65.758 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1696 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpv4NXhM/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.47851\n",
      "INFO:tensorflow:loss = 3.68502, step = 1701 (67.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.42974\n",
      "INFO:tensorflow:loss = 3.56654, step = 1801 (69.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41629\n",
      "INFO:tensorflow:loss = 4.01148, step = 1901 (70.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.52347\n",
      "INFO:tensorflow:loss = 4.17867, step = 2001 (65.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41369\n",
      "INFO:tensorflow:loss = 4.14959, step = 2101 (70.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41443\n",
      "INFO:tensorflow:loss = 3.89336, step = 2201 (70.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.45209\n",
      "INFO:tensorflow:loss = 3.93481, step = 2301 (68.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.41915\n",
      "INFO:tensorflow:loss = 3.25303, step = 2401 (70.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.36662\n",
      "INFO:tensorflow:loss = 2.23057, step = 2501 (73.171 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2553 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpv4NXhM/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.43256\n",
      "INFO:tensorflow:loss = 2.55991, step = 2601 (69.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56421\n",
      "INFO:tensorflow:loss = 3.81361, step = 2701 (63.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50826\n",
      "INFO:tensorflow:loss = 3.76922, step = 2801 (66.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.50255\n",
      "INFO:tensorflow:loss = 3.60379, step = 2901 (66.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.38324\n",
      "INFO:tensorflow:loss = 3.84229, step = 3001 (72.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.35913\n",
      "INFO:tensorflow:loss = 3.84259, step = 3101 (73.574 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3152 into /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpv4NXhM/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.89695.\n",
      "input shape: (?, 256, 3, 1)\n",
      "conv1 shpae: (?, 256, 3, 32)\n",
      "pool1 shape: (?, 127, 3, 32)\n",
      "conv2 shpae: (?, 127, 3, 64)\n",
      "pool2 shape: (?, 62, 3, 64)\n",
      "conv3 shpae: (?, 62, 3, 128)\n",
      "pool3 shape: (?, 30, 3, 128)\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/30/zm33lx8x6673tx7yywr96tr80000gn/T/tmpv4NXhM/model.ckpt-3152\n",
      "----Best setting----\n",
      "batch_size   ==>   128\n",
      "dense_units  ==> 128.000000\n",
      "kernel2_width ==> 2.000000\n",
      "dropout      ==> 0.100000\n",
      "pool2_width  ==> 4.000000\n",
      "pool1_stride ==> 2.000000\n",
      "nclasses     ==> 71.000000\n",
      "pool2_stride ==> 2.000000\n",
      "kernel1_width ==> 2.000000\n",
      "pool1_width  ==> 4.000000\n",
      "\n",
      "\n",
      "                                                                         precision    recall  f1-score   support\n",
      "\n",
      "                                                              text/html       0.64      0.36      0.46      3000\n",
      "                                                              image/png       0.61      0.69      0.65      3000\n",
      "                                                    application/rss+xml       0.00      0.00      0.00      1511\n",
      "                                                  application/xhtml+xml       0.97      0.36      0.53      3000\n",
      "                                                        application/pdf       1.00      0.00      0.01      3000\n",
      "                                                             text/plain       0.73      0.50      0.60      3000\n",
      "                                                             image/jpeg       0.31      0.94      0.46      3000\n",
      "                                                              image/bmp       0.00      0.00      0.00        11\n",
      "                                                        application/xml       0.00      0.00      0.00      1128\n",
      "                                                              image/gif       0.19      0.70      0.30      3000\n",
      "                                                            video/x-flv       0.00      0.00      0.00         3\n",
      "                                                          image/svg+xml       0.00      0.00      0.00        57\n",
      "                                                          text/x-matlab       0.00      0.00      0.00       203\n",
      "                                               application/vnd.ms-excel       0.00      0.00      0.00        15\n",
      "      application/vnd.openxmlformats-officedocument.spreadsheetml.sheet       0.00      0.00      0.00         7\n",
      "                                                     application/msword       0.00      0.00      0.00        52\n",
      "                                               image/vnd.microsoft.icon       0.00      0.00      0.00       269\n",
      "                                                             audio/mpeg       0.00      0.00      0.00       119\n",
      "                                                 application/postscript       0.00      0.00      0.00        43\n",
      "                                   application/vnd.google-earth.kml+xml       0.00      0.00      0.00        50\n",
      "                                                             text/x-php       0.00      0.00      0.00         5\n",
      "                                                          text/calendar       0.00      0.00      0.00        13\n",
      "                                                    application/rdf+xml       0.00      0.00      0.00       186\n",
      "                                                        application/zip       0.00      0.00      0.00       308\n",
      "                                                   application/atom+xml       0.00      0.00      0.00       532\n",
      "                                            application/x-tika-msoffice       0.00      0.00      0.00       101\n",
      "                                               application/x-tika-ooxml       0.00      0.00      0.00       241\n",
      "application/vnd.openxmlformats-officedocument.wordprocessingml.document       0.00      0.00      0.00        23\n",
      "                                                        video/quicktime       0.00      0.00      0.00       182\n",
      "                                                   application/x-netcdf       0.00      0.00      0.00         5\n",
      "                                               application/octet-stream       0.00      0.00      0.00       451\n",
      "                                                      application/x-elc       0.00      0.00      0.00        53\n",
      "                                                   application/epub+zip       0.00      0.00      0.00         6\n",
      "                                                              video/mp4       0.00      0.00      0.00       124\n",
      "                                  application/x-msdownload; format=pe32       0.00      0.00      0.00         3\n",
      "                                                    application/x-bzip2       0.00      0.00      0.00        13\n",
      "                                                     application/x-gtar       0.00      0.00      0.00         9\n",
      "                                               application/x-msdownload       0.00      0.00      0.00        15\n",
      "                                                       application/zlib       0.00      0.00      0.00         5\n",
      "                                       application/vnd.google-earth.kmz       0.00      0.00      0.00        10\n",
      "                                         application/x-bibtex-text-file       0.00      0.00      0.00        27\n",
      "                                                       application/gzip       0.00      0.00      0.00       320\n",
      "                                                                      0       0.00      0.00      0.00         3\n",
      "                                                             video/mpeg       0.00      0.00      0.00        47\n",
      "                                                         video/x-ms-wmv       0.00      0.00      0.00        25\n",
      "                                          application/x-shockwave-flash       0.00      0.00      0.00        25\n",
      "                                                            video/x-m4v       0.00      0.00      0.00        34\n",
      "                                                      application/x-hdf       0.00      0.00      0.00         6\n",
      "                                                 application/x-compress       0.00      0.00      0.00         8\n",
      "                                               application/x-executable       0.00      0.00      0.00         7\n",
      "                                                             image/tiff       0.00      0.00      0.00        90\n",
      "                                                        video/x-msvideo       0.00      0.00      0.00        16\n",
      "                                                            text/x-perl       0.00      0.00      0.00         3\n",
      "                                                         message/rfc822       0.00      0.00      0.00        42\n",
      "                                                            audio/x-wav       0.00      0.00      0.00        12\n",
      "                                           application/vnd.rn-realmedia       0.00      0.00      0.00        21\n",
      "                                                        application/rtf       0.00      0.00      0.00         9\n",
      "                                                      application/x-tar       0.00      0.00      0.00         7\n",
      "                                                 application/x-matroska       0.00      0.00      0.00        13\n",
      "                                                    application/dif+xml       0.00      0.00      0.00       582\n",
      "                                                       application/x-sh       0.00      0.00      0.00       214\n",
      "                                                         video/x-ms-asf       0.00      0.00      0.00         5\n",
      "                                                            audio/basic       0.00      0.00      0.00        11\n",
      "                                                       application/mbox       0.00      0.00      0.00        10\n",
      "                                                           text/x-vcard       0.00      0.00      0.00         3\n",
      "                                                       application/fits       0.00      0.00      0.00        10\n",
      "                                          application/vnd.ms-powerpoint       0.00      0.00      0.00         5\n",
      "                                            application/x-endnote-refer       0.00      0.00      0.00        16\n",
      "                                                         audio/x-ms-wma       0.00      0.00      0.00        11\n",
      "                                   application/dita+xml; format=concept       0.00      0.00      0.00        64\n",
      "                                                              audio/mp4       0.00      0.00      0.00         4\n",
      "\n",
      "                                                            avg / total       0.47      0.38      0.32     28403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_param = results[0]\n",
    "batch_size = best_param[1]\n",
    "config['dropout'] = best_param[2]\n",
    "config['dense_units'] = best_param[3]\n",
    "config['kernel1_width'] = best_param[4]\n",
    "config['kernel2_width'] = best_param[4]\n",
    "config['pool1_width'] = best_param[5]\n",
    "config['pool2_width'] = best_param[5]\n",
    "config['pool1_stride'] = best_param[6]\n",
    "config['pool2_stride'] = best_param[6]\n",
    "\n",
    "# Create the Estimator\n",
    "cnn_classifier = tf.estimator.Estimator(\n",
    "model_fn=cnn_model_fn, model_dir=None, params=config)\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=5000) \n",
    "\n",
    "#make full training data\n",
    "train_full_data = np.vstack((train_data,dev_data))\n",
    "train_full_labels = np.hstack((train_labels,dev_labels))\n",
    "train_full_data = scaler.fit_transform(train_full_data)\n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": train_full_data},\n",
    "  y=train_full_labels,\n",
    "  batch_size=batch_size,\n",
    "  num_epochs=3,\n",
    "  shuffle=True)\n",
    "\n",
    "steps = train_full_data.shape[0]/batch_size\n",
    "cnn_classifier.train(\n",
    "  input_fn=train_input_fn,\n",
    "  steps=None, # 60000\n",
    "  hooks=[logging_hook])\n",
    "\n",
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_data},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "predictions = cnn_classifier.predict(input_fn=pred_input_fn)\n",
    "predictions = list(p[\"classes\"] for p in predictions)\n",
    "\n",
    "print ('----Best setting----')\n",
    "print('{0:12} ==> {1:5d}'.format('batch_size', batch_size))\n",
    "for k,v in config.iteritems():\n",
    "    print('{0:12} ==> {1:5f}'.format(k, v))  \n",
    "print ('\\n')\n",
    "\n",
    "target_names = np.unique(test_labels)\n",
    "target_names = np.sort(target_names)\n",
    "target_names = [idx_to_ft[i] for i in target_names]\n",
    "print (classification_report(test_labels, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37538288209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(test_labels, predictions,normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
